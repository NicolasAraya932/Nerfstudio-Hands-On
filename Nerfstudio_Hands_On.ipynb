{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiiXJ7K_fePG"
      },
      "source": [
        "<p align=\"justify\">\n",
        "    <picture>\n",
        "        <source srcset=\"https://icra25lasat.ieeechile.cl/images/icra25la.png\">\n",
        "        <img alt=\"nerfstudio\" src=\"\thttps://icra25lasat.ieeechile.cl/images/icra25la.png\" width=\"400\">\n",
        "    </picture>\n",
        "    <picture>\n",
        "        <img alt=\"nerfstudio\" src=\"https://icra25lasat.ieeechile.cl/images/uoh.png\" width=\"100\">\n",
        "    </picture>\n",
        "</p>\n",
        "\n",
        "<p align=\"left\">\n",
        "    <picture>\n",
        "    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://docs.nerf.studio/_images/logo-dark.png\">\n",
        "    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://docs.nerf.studio/_images/logo.png\">\n",
        "    <img alt=\"nerfstudio\" src=\"https://docs.nerf.studio/_images/logo.png\" width=\"400\">\n",
        "    </picture>\n",
        "</p>\n",
        "# Nerfstudio: A collaboration friendly studio for NeRFs frameworks\n",
        "\n",
        "\n",
        "![GitHub stars](https://img.shields.io/github/stars/nerfstudio-project/nerfstudio?color=gold&style=social)\n",
        "\n",
        "This colab shows how to train and view NeRFs from Nerfstudio both on pre-made datasets or from your own videos/images.\n",
        "\n",
        "\\\\\n",
        "\n",
        "Credit to [NeX](https://nex-mpi.github.io/) for Google Colab format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yyx5h6kz5ga7"
      },
      "source": [
        "## Frequently Asked Questions\n",
        "\n",
        "*  **Downloading custom data is stalling (no output):**\n",
        "    * This is a bug in Colab. The data is processing, but may take a while to complete. You will know processing completed if `data/nerfstudio/custom_data/transforms.json` exists. Terminating the cell early will result in not being able to train.\n",
        "*  **Processing custom data is taking a long time:**\n",
        "    * The time it takes to process data depends on the number of images and its resolution. If processing is taking too long, try lowering the resolution of your custom data.\n",
        "*  **Error: Data processing did not complete:**\n",
        "    * This means that the data processing script did not fully complete. This could be because there were not enough images, or that the images were of low quality. We recommend images with little to no motion blur and lots of visual overlap of the scene to increase the chances of successful processing.\n",
        "*   **Training is not showing progress**:\n",
        "    * The lack of output is a bug in Colab. You can see the training progress from the viewer.\n",
        "* **Viewer Quality is bad / Low resolution**:\n",
        "    * This may be because more GPU is being used on training that rendering the viewer. Try pausing training or decreasing training utilization.\n",
        "* **WARNING: Running pip as the 'root' user...:**:\n",
        "    * This and other pip warnings or errors can be safely ignored.\n",
        "* **Other problems?**\n",
        "    * Feel free to create an issue on our [GitHub repo](https://github.com/nerfstudio-project/nerfstudio).\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Install Pixi { vertical-output: true }\n",
        "from IPython.display import Markdown, display\n",
        "from rich.console import Console\n",
        "from rich.progress import Progress, TextColumn, BarColumn, TaskProgressColumn, TimeRemainingColumn\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "# Ensure rich is installed (this step won't be shown in progress)\n",
        "subprocess.run(\"pip install rich\", shell=True, check=True)\n",
        "\n",
        "console = Console()\n",
        "step_cmds = [\n",
        "    (\"Change to /content\", [\"cd /content/\"]),\n",
        "    (\"Download & Install Pixi\", [\"curl -fsSL https://pixi.sh/install.sh | sh\"]),\n",
        "    (\"Add Pixi to PATH\", []),  # handled in Python\n",
        "    (\"Verify Pixi version\", [\"pixi --version\"]),\n",
        "    (\"Initialize Pixi Project\", [\"pixi init .\"]),\n",
        "]\n",
        "\n",
        "display(Markdown(\"**Installing Pixi...**\"))\n",
        "with Progress(\n",
        "    TextColumn(\":sparkles: {task.description}\"),\n",
        "    BarColumn(),\n",
        "    TaskProgressColumn(),\n",
        "    TimeRemainingColumn(),\n",
        "    console=console,\n",
        "    transient=True,\n",
        ") as progress:\n",
        "    task = progress.add_task(\"Total steps\", total=len(step_cmds))\n",
        "    for desc, cmds in step_cmds:\n",
        "        console.print(f\"\\n[bold cyan]Step:[/] {desc}\")\n",
        "        if desc == \"Add Pixi to PATH\":\n",
        "            # Modify PATH in current session\n",
        "            os.environ[\"PATH\"] += \":/root/.pixi/bin\"\n",
        "        else:\n",
        "            for cmd in cmds:\n",
        "                # use bash for cd commands\n",
        "                subprocess.run(cmd, shell=True, check=True, cwd=\"/content/\", env=os.environ)\n",
        "        progress.advance(task)\n",
        "\n",
        "# Final confirmation\n",
        "display(Markdown(\"**Pixi installation complete!**\"))\n"
      ],
      "metadata": {
        "id": "uOhYdAXSawJe",
        "collapsed": true,
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oyLHl8QfYwP",
        "collapsed": true,
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title # Dependencies { vertical-output: true }\n",
        "# @markdown <h1>Install Nerfstudio and Dependencies (~8â€¯min)</h1>\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "from rich.console import Console\n",
        "from rich.progress import Progress, TextColumn, BarColumn, TaskProgressColumn, TimeRemainingColumn\n",
        "import subprocess\n",
        "import time\n",
        "import os\n",
        "\n",
        "# Initialize Rich console and progress\n",
        "console = Console()\n",
        "steps = [\n",
        "    (\"Add Python & Pip to Pixi\", [\"pixi add --manifest-path pixi.toml python=3.10 pip\"]),\n",
        "    (\"Upgrade Pip\", [\"pixi run --manifest-path pixi.toml pip install --upgrade pip\"]),\n",
        "    (\"Install PyTorch & Torchaudio\", [\n",
        "        \"pixi run --manifest-path pixi.toml pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 \\\n",
        "            torchaudio==2.0.2+cu118 --extra-index-url https://download.pytorch.org/whl/cu118\"\n",
        "    ]),\n",
        "    (\"Download TinyCudaNN Wheel\", [\n",
        "        \"gdown https://drive.google.com/u/1/uc?id=1-7x7qQfB7bIw2zV4Lr6-yhvMpjXC84Q5&confirm=t\"\n",
        "    ]),\n",
        "    (\"Install TinyCudaNN\", [\n",
        "        \"pixi run --manifest-path pixi.toml pip install tinycudann-1.7-cp310-cp310-linux_x86_64.whl\"\n",
        "    ]),\n",
        "    (\"Install COLMAP\", [\"pixi run --manifest-path pixi.toml apt-get install -y colmap\"]),\n",
        "    (\"Install Nerfstudio\", [\n",
        "        \"pixi run --manifest-path pixi.toml pip install git+https://github.com/nerfstudio-project/nerfstudio.git\"\n",
        "    ]),\n",
        "    (\"Solving Numpy Bug\", [\"pixi run --manifest-path pixi.toml pip install numpy==1.26.4\"]),\n",
        "]\n",
        "\n",
        "display(Markdown(\"**Installing dependencies...**\"))\n",
        "\n",
        "with Progress(\n",
        "    TextColumn(\"[:rocket:] {task.description}\"),\n",
        "    BarColumn(),\n",
        "    TaskProgressColumn(),\n",
        "    TimeRemainingColumn(),\n",
        "    console=console,\n",
        "    transient=True,\n",
        ") as progress_bar:\n",
        "    task = progress_bar.add_task(\"Total steps\", total=len(steps))\n",
        "    for desc, cmds in steps:\n",
        "        # Display step description\n",
        "        console.print(f\"\\n[bold cyan]Step:[/] {desc}\")\n",
        "        for cmd in cmds:\n",
        "            # Run each shell command\n",
        "            process = subprocess.run(cmd, shell=True, cwd=\"/content/\", env=os.environ)\n",
        "            if process.returncode != 0:\n",
        "                console.print(f\"[bold red]Error running:[/] {cmd}\")\n",
        "                raise RuntimeError(f\"Step failed: {desc}\")\n",
        "            if \"TinyCudaNN Wheel\" in desc:\n",
        "                time.sleep(10)\n",
        "        progress_bar.advance(task)\n",
        "\n",
        "# Final message\n",
        "display(Markdown(\"**DONE**\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msVLprI4gRA4",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title # Downloading and Processing Data { vertical-output : true }\n",
        "# @markdown <h3>Pick the preset scene or upload your own images/video</h3>\n",
        "import glob\n",
        "import os\n",
        "\n",
        "from google.colab import files\n",
        "from IPython.core.display import HTML, display\n",
        "\n",
        "scene = \"\\ud83d\\uddbc poster\"  # @param ['ðŸ–¼ poster', 'ðŸšœ dozer', 'ðŸŒ„ desolation', 'ðŸ“¤ upload your images' , 'ðŸŽ¥ upload your own video', 'ðŸ”º upload Polycam data', 'ðŸ’½ upload your own Record3D data']\n",
        "scene = \" \".join(scene.split(\" \")[1:])\n",
        "\n",
        "if scene == \"upload Polycam data\":\n",
        "    %cd /content/\n",
        "    !mkdir -p /content/data/nerfstudio/custom_data\n",
        "    %cd /content/data/nerfstudio/custom_data/\n",
        "    uploaded = files.upload()\n",
        "    dir = os.getcwd()\n",
        "    if len(uploaded.keys()) > 1:\n",
        "        print(\"ERROR, upload a single .zip file when processing Polycam data\")\n",
        "    dataset_dir = [os.path.join(dir, f) for f in uploaded.keys()][0]\n",
        "    !pixi run --manifest-path pixi.toml ns-process-data polycam --data $dataset_dir --output-dir /content/data/nerfstudio/custom_data/\n",
        "    scene = \"custom_data\"\n",
        "elif scene == \"upload your own Record3D data\":\n",
        "    display(HTML(\"<h3>Zip your Record3D folder, and upload.</h3>\"))\n",
        "    display(\n",
        "        HTML(\n",
        "            '<h3>More information on Record3D can be found <a href=\"https://docs.nerf.studio/en/latest/quickstart/custom_dataset.html#record3d-capture\" target=\"_blank\">here</a>.</h3>'\n",
        "        )\n",
        "    )\n",
        "    %cd /content/\n",
        "    !mkdir -p /content/data/nerfstudio/custom_data\n",
        "    %cd /content/data/nerfstudio/custom_data/\n",
        "    uploaded = files.upload()\n",
        "    dir = os.getcwd()\n",
        "    preupload_datasets = [os.path.join(dir, f) for f in uploaded.keys()]\n",
        "    record_3d_zipfile = preupload_datasets[0]\n",
        "    !unzip $record_3d_zipfile -d /content/data/nerfstudio/custom_data\n",
        "    custom_data_directory = glob.glob(\"/content/data/nerfstudio/custom_data/*\")[0]\n",
        "    !pixi run --manifest-path pixi.toml ns-process-data record3d --data $custom_data_directory --output-dir /content/data/nerfstudio/custom_data/\n",
        "    scene = \"custom_data\"\n",
        "elif scene in [\"upload your images\", \"upload your own video\"]:\n",
        "    display(HTML(\"<h3>Select your custom data</h3>\"))\n",
        "    display(HTML(\"<p/>You can select multiple images by pressing ctrl, cmd or shift and click.<p>\"))\n",
        "    display(\n",
        "        HTML(\n",
        "            \"<p/>Note: This may take time, especially on higher resolution inputs, so we recommend to download dataset after creation.<p>\"\n",
        "        )\n",
        "    )\n",
        "    !mkdir -p /content/data/nerfstudio/custom_data\n",
        "    if scene == \"upload your images\":\n",
        "        !mkdir -p /content/data/nerfstudio/custom_data/raw_images\n",
        "        %cd /content/data/nerfstudio/custom_data/raw_images\n",
        "        uploaded = files.upload()\n",
        "        dir = os.getcwd()\n",
        "    else:\n",
        "        %cd /content/data/nerfstudio/custom_data/\n",
        "        uploaded = files.upload()\n",
        "        dir = os.getcwd()\n",
        "    preupload_datasets = [os.path.join(dir, f) for f in uploaded.keys()]\n",
        "    del uploaded\n",
        "    %cd /content/\n",
        "\n",
        "    if scene == \"upload your images\":\n",
        "        !pixi run --manifest-path pixi.toml ns-process-data images --data /content/data/nerfstudio/custom_data/raw_images --output-dir /content/data/nerfstudio/custom_data/\n",
        "    else:\n",
        "        video_path = preupload_datasets[0]\n",
        "        !pixi run --manifest-path pixi.toml ns-process-data video --data $video_path --output-dir /content/data/nerfstudio/custom_data/\n",
        "\n",
        "    scene = \"custom_data\"\n",
        "else:\n",
        "    %cd /content/\n",
        "    !pixi run --manifest-path pixi.toml ns-download-data nerfstudio --capture-name=$scene\n",
        "\n",
        "print(\"Data Processing Succeeded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGt8ukG6Htg3",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title # Start Training (~ 10 min every 10k train iterations){ vertical-output : true }\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "from collections import deque\n",
        "\n",
        "from rich.console import Console\n",
        "from rich.live import Live\n",
        "from rich.panel import Panel\n",
        "\n",
        "console = Console()\n",
        "\n",
        "display(Markdown(\"[viser generated link](https://xxxxxxxxx.share.viser.studio/)\"))\n",
        "\n",
        "# Example command that streams output\n",
        "cmd = (\n",
        "    \"pixi run --manifest-path pixi.toml \"\n",
        "    \"ns-train nerfacto \"\n",
        "    \"--viewer.websocket-port 7007 \"\n",
        "    \"--viewer.make-share-url True \"\n",
        "    \"--max-num-iterations 10000 \"\n",
        "    f\"nerfstudio-data --data data/nerfstudio/{scene} \"\n",
        "    \"--downscale-factor 4 \"\n",
        ")\n",
        "\n",
        "# Prepare a deque to hold up to 10 lines\n",
        "last_lines = deque(maxlen=15)\n",
        "\n",
        "# Launch the process\n",
        "process = subprocess.Popen(\n",
        "    cmd,\n",
        "    shell=True,\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.STDOUT,\n",
        "    text=True,\n",
        "    bufsize=1,\n",
        "    env={**os.environ, \"PYTHONUNBUFFERED\": \"1\"},\n",
        ")\n",
        "\n",
        "# Use Live to continuously update the panel\n",
        "with Live(Panel(\"Waiting for output...\"), console=console, refresh_per_second=4) as live:\n",
        "    for line in process.stdout:\n",
        "        # Strip and append the new line\n",
        "        last_lines.append(line.rstrip())\n",
        "        # Update the panel with the joined last 10 lines\n",
        "        live.update(Panel(\"\\n\".join(last_lines)))\n",
        "\n",
        "# Wait for the process to finish\n",
        "process.wait()\n",
        "console.print(f\"[bold green]Process exited with code {process.returncode}[/]\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title # Render Video { vertical-output: true }\n",
        "# @markdown <h3>Export the camera path from within the viewer, then run this cell.</h3>\n",
        "# @markdown <h5>The rendered video should be at renders/output.mp4!</h5>\n",
        "\n",
        "\n",
        "base_dir = \"/content/outputs/unnamed/nerfacto/\"\n",
        "training_run_dir = base_dir + os.listdir(base_dir)[0]\n",
        "\n",
        "from IPython.core.display import HTML, display\n",
        "\n",
        "display(HTML(\"<h3>Upload the camera path JSON.</h3>\"))\n",
        "%cd $training_run_dir\n",
        "uploaded = files.upload()\n",
        "uploaded_camera_path_filename = list(uploaded.keys())[0]\n",
        "\n",
        "config_filename = training_run_dir + \"/config.yml\"\n",
        "camera_path_filename = training_run_dir + \"/\" + uploaded_camera_path_filename\n",
        "camera_path_filename = camera_path_filename.replace(\" \", \"\\\\ \").replace(\"(\", \"\\\\(\").replace(\")\", \"\\\\)\")\n",
        "\n",
        "%cd /content/\n",
        "!pixi run --manifest-path pixi.toml ns-render camera-path --load-config $config_filename --camera-path-filename $camera_path_filename --output-path renders/output.mp4\n"
      ],
      "metadata": {
        "id": "9FuoeA5Wiukg",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Challenge: Create and train your own datset\n",
        "\n",
        "## Steps:\n",
        "\n",
        "* Record a Video\n",
        "* Use ns-process-data\n",
        "    * Tip: To analyze \"Downloading and Processing Data\"\n",
        "        * !pixi run --manifest-path pixi.toml ns-process-data polycam --data $dataset_dir --output-dir /content/data/nerfstudio/custom_data/\n",
        "* Train Nerfacto with your own data\n",
        "* Optional: Render a Video!"
      ],
      "metadata": {
        "id": "PPmScCCgoO93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <h2>Capture and then Upload the Video</h2>\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "# Opens a fileâ€‘picker dialog; returns a dict of filenameâ†’fileâ€‘bytes\n",
        "%cd /content/\n",
        "uploaded_video = files.upload()"
      ],
      "metadata": {
        "id": "aSLiP67JmkSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title # Process Data\n",
        "# @markdown ## Complete the Code\n",
        "\n",
        "\"\"\"To specify the video path\"\"\"\n",
        "video_path = \"/content/...\"\n",
        "\n",
        "!pixi run --manifest-path pixi.toml ns-process-data video --data $video_path  --output-dir \"\"\"To specify your output path\"\"\"\n"
      ],
      "metadata": {
        "id": "N_L2zFNgoXqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title # Training Nerf\n",
        "# @markdown ## Complete the Code\n",
        "\n",
        "data_path = \"/content/...\"\n",
        "\n",
        "!pixi run --manifest-path pixi.toml ns-train nerfacto --viewer.websocket-port 7007 --viewer.make-share-url True --max-num-iterations 10000 nerfstudio-data --data $data_path --downscale-factor 4\n"
      ],
      "metadata": {
        "id": "7qZrmz5LxPOm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.13 ('nerfstudio')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "c59f626636933ef1dc834fb3684b382f705301c5306cf8436d2da634c2289783"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}